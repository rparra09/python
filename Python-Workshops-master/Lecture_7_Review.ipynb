{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lecture-7-Review.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "3m4eiHF9aOOF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Python3 - Workshop #7\n",
        "Opening and Working with data files"
      ]
    },
    {
      "metadata": {
        "id": "QEU0Xybyagv9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Is NASA a waste of money?\n",
        "Watch: https://www.youtube.com/watch?v=lARpY0nIQx0\n",
        "\n",
        "![USA Buget](https://preview.ibb.co/gpyPkq/nasa-budget.png)"
      ]
    },
    {
      "metadata": {
        "id": "QGjmic2Za5AB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Importing Data from Google Drive (sheets)"
      ]
    },
    {
      "metadata": {
        "id": "BgttjTHkuI_2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install --upgrade -q gspread"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fjDmiqBmuJBY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "01ef77d2-5556-4da0-af3d-0808b95986cc"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "worksheet = gc.open('Accelerometer-Data').sheet1\n",
        "\n",
        "# get_all_values gives a list of rows.\n",
        "excelData = worksheet.get_all_values()\n",
        "#print(myData)\n",
        "\n",
        "# Convert to a DataFrame and render.\n",
        "#import pandas as pd\n",
        "#pd.DataFrame.from_records(myData)\n",
        "\n",
        "dataDescription = excelData[3]\n",
        "\n",
        "print(dataDescription)\n",
        "\n",
        "\n",
        "# save the data in a list\n",
        "myData = []\n",
        "\n",
        "for row in excelData[4:len(excelData)]:\n",
        "  myData.append(row)\n",
        "  \n",
        "# print(myData)\n",
        "# do math to the list myData\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Time (s)', 'X (m/s2)', 'Y (m/s2)', 'Z (m/s2)', 'R (m/s2)', 'Theta (deg)', 'Phi (deg)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SRwp86aRb4W8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Opening CSV and TXT in Ubuntu/Noob's Raspberry Pi\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "0FS77M93eHO_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "with open('class-data.csv') as csvfile:\n",
        "  myData = csv.reader(csvfile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p3M4eQP9xkhK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "with open('class-data.txt') as csvfile:\n",
        "  myData = csv.reader(csvfile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "02iQOZzsydRB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Opening HDF5 Files\n",
        "H5py lets you store huge amounts of numerical data, and easily manipulate that data from NumPy. For example, you can slice into multi-terabyte datasets stored on disk, as if they were real NumPy arrays. Thousands of datasets can be stored in a single file, categorized and tagged however you want.\n",
        "\n",
        "*   **Info**: https://www.h5py.org/\n",
        "*   **API**: http://docs.h5py.org/en/stable/\n",
        "\n",
        "I highly recommend you read the book: http://a.co/d/bD9dsvP"
      ]
    },
    {
      "metadata": {
        "id": "b4folPRMyfEz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  Method 1\n",
        "\"\"\"\n",
        "\n",
        "# copy paste the file name\n",
        "fileName = 'merra-data.hdf5'\n",
        "\n",
        "with h5py.File(fileName, 'r') as myFile:\n",
        "\tprint(myFile.name)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "  Method 2\n",
        "\"\"\"  \n",
        "  \n",
        "f = h5py.File(fileName, 'r')\n",
        "\n",
        "print(f['2010/12/31/BCSMASS'])\n",
        "\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fvHWrRAL7z3w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Opening NetCDF4 Files\n",
        "NetCDF is a set of software libraries and self-describing, machine-independent data formats that support the creation, access, and sharing of array-oriented scientific data.\n",
        "\n",
        "*   **Info**: https://www.unidata.ucar.edu/software/netcdf/docs/\n",
        "*   **API**: http://unidata.github.io/netcdf4-python/#section1\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "D54oOAfd70Ob",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  I don't know how to get netCDF4 to work on colab.research.google.com\n",
        "  You need to install it on a linux machine. Please read the installation notes\n",
        "    on the class raspberri pi\n",
        "  \n",
        "  This is an example on how to open netCDF4 files in python\n",
        "\"\"\"\n",
        "\n",
        "import netCDF4\n",
        "\n",
        "# copy paste the file name \n",
        "fileName = 'g4.timeAvgMap.M2TMNXAER_5_12_4_BCSMASS.20170101-20170131.180W_90S_180E_90N.nc'\n",
        "\n",
        "# open the file as READ ONLY\n",
        "# read the API - http://unidata.github.io/netcdf4-python/#section1\n",
        "satelliteData = netCDF4.Dataset(fileName, 'r') \n",
        "\n",
        "print(satelliteData.data_model)\n",
        "print(satelliteData.variables)\n",
        "\n",
        "satelliteData.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6_nuO8z5H9yy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Output**\n",
        "\n",
        "```\n",
        "NETCDF4_CLASSIC\n",
        "OrderedDict([('M2TMNXAER_5_12_4_BCSMASS', <class 'netCDF4._netCDF4.Variable'>\n",
        "float32 M2TMNXAER_5_12_4_BCSMASS(lat, lon)\n",
        "    _FillValue: 1e+15\n",
        "    fmissing_value: 1e+15\n",
        "    fullnamepath: /BCSMASS\n",
        "    missing_value: 1e+15\n",
        "    origname: BCSMASS\n",
        "    vmax: 1e+15\n",
        "    vmin: -1e+15\n",
        "    standard_name: m2tmnxaer_5_12_4_bcsmass\n",
        "    quantity_type: Black Carbon\n",
        "    product_short_name: M2TMNXAER\n",
        "    product_version: 5.12.4\n",
        "    long_name: Black Carbon Surface Mass Concentration\n",
        "    units: kg m-3\n",
        "    cell_methods: time: mean\n",
        "    latitude_resolution: 0.5\n",
        "    longitude_resolution: 0.625\n",
        "    coordinates: lat lon\n",
        "unlimited dimensions: \n",
        "current shape = (361, 576)\n",
        "filling on), ('lat', <class 'netCDF4._netCDF4.Variable'>\n",
        "float64 lat(lat)\n",
        "    units: degrees_north\n",
        "    vmax: 1e+15\n",
        "    vmin: -1e+15\n",
        "    origname: lat\n",
        "    fullnamepath: /lat\n",
        "    standard_name: latitude\n",
        "    bounds: lat_bnds\n",
        "unlimited dimensions: \n",
        "current shape = (361,)\n",
        "filling on, default _FillValue of 9.969209968386869e+36 used\n",
        "), ('lat_bnds', <class 'netCDF4._netCDF4.Variable'>\n",
        "float64 lat_bnds(lat, latv)\n",
        "    units: degrees_north\n",
        "unlimited dimensions: \n",
        "current shape = (361, 2)\n",
        "filling on, default _FillValue of 9.969209968386869e+36 used\n",
        "), ('lon', <class 'netCDF4._netCDF4.Variable'>\n",
        "float64 lon(lon)\n",
        "    units: degrees_east\n",
        "    vmax: 1e+15\n",
        "    vmin: -1e+15\n",
        "    origname: lon\n",
        "    fullnamepath: /lon\n",
        "    standard_name: longitude\n",
        "    bounds: lon_bnds\n",
        "unlimited dimensions: \n",
        "current shape = (576,)\n",
        "filling on, default _FillValue of 9.969209968386869e+36 used\n",
        "), ('lon_bnds', <class 'netCDF4._netCDF4.Variable'>\n",
        "float64 lon_bnds(lon, lonv)\n",
        "    units: degrees_east\n",
        "unlimited dimensions: \n",
        "current shape = (576, 2)\n",
        "filling on, default _FillValue of 9.969209968386869e+36 used\n",
        ")])\n",
        "\n",
        "\n",
        "------------------\n",
        "(program exited with code: 0)\n",
        "Press return to continue\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "-vsyNwtQVhXt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Database Storage Structure\n",
        "Always take a look at your data BEFORE you start coding. You need to know what you are working with so you can attack problem correctly.\n",
        "\n",
        "\n",
        "\n",
        "*  I reccomend [ViTables](http://vitables.org/): \"ViTables is a graphical tool for browsing and editing files in both PyTables and HDF5 format. With ViTables you can easily navigate through the data hierarchy, view and modify metadata, view actual data and more.\"\n",
        "\n",
        "\n",
        "*  To view nasa files I recommend [Panoply](https://www.giss.nasa.gov/tools/panoply/): \"Panoply plots geo-referenced and other arrays from netCDF, HDF, GRIB, and other datasets.\"\n"
      ]
    },
    {
      "metadata": {
        "id": "czTxBPfPUMuJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## How HDF5 files look\n",
        "They look like files within a folder. I like to store the data just like simple python lists.\n",
        "\n",
        "![HDF5 file](https://image.ibb.co/cdgPqq/hdf5-database.png)"
      ]
    },
    {
      "metadata": {
        "id": "Kvn1m1hAUtYQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## How a NASA netCDF4 files looks like\n",
        "Nasa likes to complicate things, but they can access their data faster with a Super computer. When working from home, speed shouldn't be an issue. Just let your script run overnight and don't bother optimizing your code for speed.\n",
        "![alt text](https://image.ibb.co/dFweOA/nasa-file.png)"
      ]
    },
    {
      "metadata": {
        "id": "TPXWObdTc4hz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Nasa Database Files\n",
        "\n",
        "\n",
        "1.   **How to access the data:** https://disc.gsfc.nasa.gov/data-access\n",
        "2.   **Dowload data:** https://disc.gsfc.nasa.gov/\n",
        "3.   **Technical Information:** https://gmao.gsfc.nasa.gov/pubs/docs/Bosilovich785.pdf\n",
        "\n",
        "\n",
        "\n",
        "Nasa files are organized in the following way:\n",
        "![Nasa Files](https://disc.gsfc.nasa.gov/api/tools/Hydrology%2520Data%2520Rods/file)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "gD7Q1nJhBzNP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Opening Nasa Files\n",
        "\n",
        "Alternative to python, use: https://giovanni.gsfc.nasa.gov/giovanni/\n",
        "\n",
        "In python, the data looks like a multidimensional list, and it can take some code to process it.\n",
        "I recommend you hust copy paste my code, and change the variables."
      ]
    },
    {
      "metadata": {
        "id": "38aEbiE0dPxU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  This script handles daily MERRA-2 data\n",
        "  Author: Edgard Parra\n",
        "  Date: Summer 2017\n",
        "  \n",
        "  This script calculates PM2.5 around the world for the past 37 years.\n",
        "\"\"\"\n",
        "\n",
        "#import necessary modules\n",
        "import re\n",
        "import sys \n",
        "import h5py\n",
        "import numpy as np\n",
        "import netCDF4 as nc4\n",
        "\n",
        "# open a file, and create if it doesn't exist to store data\n",
        "f = h5py.File('merra-data.hdf5', 'w')\n",
        "\n",
        "#This finds the user's current path so that all nc4 files can be found\n",
        "try:\n",
        "\tfileList=open('myfiles.txt','r')\n",
        "except:\n",
        "\tprint('Did not find a text file containing file names (perhaps name does not match)')\n",
        "\tsys.exit()\n",
        "\n",
        "for FILE_NAME in fileList:\n",
        "\tFILE_NAME = FILE_NAME.strip()\n",
        "\t\n",
        "\tres = re.findall('aer_Nx.(\\d+)',FILE_NAME)\n",
        "\t\n",
        "\t# Find the year of the file\n",
        "\tyear = str(res[0])\n",
        "\tyear = str(year[:4])\n",
        "\t\n",
        "\t# Find the month of the year\n",
        "\tmonth = str(res[0])\n",
        "\tmonth = str(month[4:6])\n",
        "\t\n",
        "\t# Find the day of the file\n",
        "\tday = str(res[0])\n",
        "\tday = str(day[-2:])\n",
        "\t\n",
        "\t# read in the data \n",
        "\tmerraData = nc4.Dataset(FILE_NAME, 'r')\n",
        "\t\n",
        "\t# get the data variable names\n",
        "\tvariables = set(merraData.variables)\n",
        "\t\n",
        "\t# print(variables)\n",
        "\t\n",
        "\t# declare the desired variables \n",
        "\tdesiredVariables = set({'BCSMASS','DUSMASS25','OCSMASS','SO4SMASS','SSSMASS25'})\n",
        "\t\n",
        "\t# create list of variables found\n",
        "\tdesiredVariables = set([x.lower() for x in desiredVariables])\n",
        "\t\n",
        "\tvar1 = variables.intersection(desiredVariables)\n",
        "\t\n",
        "\tdesiredVariables = set([x.upper() for x in desiredVariables])\n",
        "\t\n",
        "\tvar2 = variables.intersection(desiredVariables)\n",
        "\t\n",
        "\tfileVars = list(var1.union(var2))\n",
        "\tif len(fileVars)==0:\n",
        "\t\tprint('This file contains none of the selected SDS. Skipping...')\t\t\t\n",
        "\t\tcontinue\n",
        "\tprint('Saving the following SDS from current file: \\n')\n",
        "\t[print('(' + str(fileVars.index(x)) + ')',x) for x in fileVars]\n",
        "\t\n",
        "\t#extract lat and lon info. These are just vectors in the dataset so they're repeated to accommodate the data array  \n",
        "\tlats = merraData.variables['lat'][:]\n",
        "\tlons = merraData.variables['lon'][:]\n",
        "\ttotalLon = np.tile(lons,len(lats))\n",
        "\ttotalLat = lats.repeat(len(lons))\n",
        "\t\n",
        "\t#create a matrix the same size as the lat/lon datasets to save everything \n",
        "\toutput=np.zeros((totalLat.shape[0],len(fileVars)+2))\n",
        "\toutput[:,0]=totalLat\n",
        "\toutput[:,1]=totalLon\n",
        "\t\n",
        "\t#can't combine string and floats in an array, so a list of titles is made \n",
        "\ttempOutput=[]\n",
        "\ttempOutput.append('Latitude')\n",
        "\ttempOutput.append('Longitude')\n",
        "\tindex=2\n",
        "\tfor SDS_NAME in fileVars:\n",
        "\t\ttry:\n",
        "\t\t\t#read merra data as a vector \n",
        "\t\t\tdata = merraData.variables[SDS_NAME][:]\n",
        "\t\t\t#print(len(data.shape))\n",
        "\t\texcept:\n",
        "\t\t\tprint('There is an issue with your MERRA file (might be the wrong MERRA file type). Skipping...')\n",
        "\t\t\tcontinue\n",
        "\t\tif len(data.shape) == 4:\n",
        "\t\t\tlevel = data.shape[1]-1\n",
        "\t\t\tdata = data[0,level,:,:]\n",
        "\t\telif len(data.shape) == 3:\n",
        "\t\t\tlevel = data.shape[0]-1\n",
        "\t\t\tdata = data[level,:,:]\n",
        "\t\t\n",
        "\t\t# convert from grid to list\n",
        "\t\tdata=data.ravel()\n",
        "\t\t\n",
        "\t\t# convert units from kg to ug\n",
        "\t\tdata = np.multiply(data,1000000000)\n",
        "\t\t\n",
        "\t\tfilePath = year+'/'+month+'/'+day+'/'+SDS_NAME\n",
        "\t\t\n",
        "\t\t# store the merraData into arrays in hdf5 format\n",
        "\t\tf[filePath] = data\n",
        "\t\tf.flush()\n",
        "\t\tprint('Saved ' + str(filePath) + ' succesfully! \\n')\n",
        "\t\n",
        "  # we're in hdf5 now\n",
        "  \n",
        "\tprint('Calculating PM2.5 \\n')\t\n",
        "\tBCSMASS = f[year+'/'+month+'/'+day+'/BCSMASS']\n",
        "\tDUSMASS25= f[year+'/'+month+'/'+day+'/DUSMASS25']\n",
        "\tOCSMASS = f[year+'/'+month+'/'+day+'/OCSMASS']\n",
        "\tSO4SMASS = f[year+'/'+month+'/'+day+'/SO4SMASS']\n",
        "\tSSSMASS25 = f[year+'/'+month+'/'+day+'/SSSMASS25']\n",
        "\n",
        "\t# solve for PM2.5 = [DUST] + [SS] + [BC] + 1.4[OC] + 1.375[SO4]\n",
        "\tOCSMASS = np.multiply(1.4,OCSMASS)\n",
        "\tSO4SMASS = np.multiply(1.375, SO4SMASS)\n",
        "\n",
        "\tPM25 = np.add(DUSMASS25,SSSMASS25)\n",
        "\tPM25 = np.add(PM25,BCSMASS)\n",
        "\t\n",
        "\tPM25 = np.add(PM25,OCSMASS)\n",
        "\tPM25 = np.add(PM25,SO4SMASS)\n",
        "\n",
        "\t# save our results to the hdf5 file\n",
        "\tpm25filePath = year+'/'+month+'/'+day+'/pm25'\n",
        "\tf[pm25filePath] = PM25\n",
        "\tf.flush()\n",
        "\tprint('Saved ' + str(pm25filePath) + ' succesfully! \\n')\n",
        "\n",
        "print('\\nSaving GPS locations')\n",
        "# store gps data on arrays\n",
        "f['gpsData/latitude'] = totalLat\n",
        "f['gpsData/longitude'] = totalLon\n",
        "\n",
        "# gps for plotting\n",
        "f['gpsData/lats'] = lats\n",
        "f['gpsData/lons'] = lons\n",
        "\n",
        "print('\\nAll valid variables have been saved successfully. \\n')\n",
        "\n",
        "# close the files\n",
        "f.flush()\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
